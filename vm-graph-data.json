[
    {
        "citationKey": "Deutsch:1984:IC",
        "entryType": "inproceedings",
        "entryTags": {
            "abstract": "The Smalltalk-80* programming language includes dynamic storage allocation, full upward funargs, and universally polymorphic procedures; the Smalltalk-80 programming system features interactive execution with incremental compilation, and implementation portability. These features of modern programming systems are among the most difficult to implement efficiently, even individually. A new implementation of the Smalltalk-80 system, hosted on a small microprocessor-based computer, achieves high performance while retaining complete (object code) compatibility with existing implementations. This paper discusses the most significant optimization techniques developed over the course of the project, many of which are applicable to other languages. The key idea is to represent certain runtime state (both code and data) in more than one form, and to convert between forms when needed.",
            "author": "Deutsch, L. Peter and Schiffman, Allan M.",
            "booktitle": "POPL '84: Proceedings of the 11th ACM SIGACT-SIGPLAN symposium on Principles of programming languages",
            "description": "Efficient Implementation of the Smalltalk-80 System",
            "doi": "10.1145/800017.800542",
            "isbn": "0-89791-125-3",
            "pages": "297--302",
            "publisher": "ACM",
            "series": "POPL'84",
            "title": "Efficient Implementation of the Smalltalk-80 System",
            "year": "1984",
            "url": "http://web.cs.ucla.edu/~palsberg/course/cs232/papers/DeutschSchiffman-popl84.pdf",
            "vm:shortTitle": "Inline Caches"
        },
        "line": 1
    },
    {
        "citationKey": "Chambers:89:Self",
        "entryType": "inproceedings",
        "entryTags": {
            "abstract": "We have developed and implemented techniques that double the performance of dynamically-typed object-oriented languages. Our SELF implementation runs twice as fast as the fastest Smalltalk implementation, despite SELF's lack of classes and explicit variables. To compensate for the absence of classes, our system uses implementation-level maps to transparently group objects cloned from the same prototype, providing data type information and eliminating the apparent space overhead for prototype-based systems. To compensate for dynamic typing, user-defined control structures, and the lack of explicit variables, our system dynamically compiles multiple versions of a source method, each customized according to its receiver's map. Within each version the type of the receiver is fixed, and thus the compiler can statically bind and inline all messages sent to self. Message splitting and type prediction extract and preserve even more static type information, allowing the compiler to inline many other messages. Inlining dramatically improves performance and eliminates the need to hard-wire low-level methods such as +,==, and ifTrue:. Despite inlining and other optimizations, our system still supports interactive programming environments. The system traverses internal dependency lists to invalidate all compiled methods affected by a programming change. The debugger reconstructs inlined stack frames from compiler-generated debugging information, making inlining invisible to the SELF programmer.",
            "author": "Chambers, Craig and Ungar, David and Lee, Elgin",
            "booktitle": "Proceedings on Object-Oriented Programming Systems, Languages and Applications",
            "doi": "10.1145/74878.74884",
            "isbn": "0-89791-333-7",
            "issn": "0362-1340",
            "month": "October",
            "pages": "49--70",
            "publisher": "ACM",
            "series": "OOPSLA'89",
            "title": "An Efficient Implementation of SELF a Dynamically-Typed Object-Oriented Language Based on Prototypes",
            "year": "1989",
            "url": "https://bibliography.selflanguage.org/_static/implementation.pdf",
            "vm:concepts": "Object Representation",
            "vm:shortTitle": "SELF & Maps",
            "vm:edge:extends": "ObjectRepresentation + efficient access and lower memory footprint"
        },
        "line": 18
    },
    {
        "citationKey": "Hoelzle:91:PIC",
        "entryType": "inproceedings",
        "entryTags": {
            "abstract": "Polymorphic inline caches (PICs) provide a new way to reduce the overhead of polymorphic message sends by extending inline caches to include more than one cached lookup result per call site. For a set of typical object-oriented SELF programs, PICs achieve a median speedup of 11%. As an important side effect, PICs collect type information by recording all of the receiver types actually used at a given call site. The compiler can exploit this type information to generate better code when recompiling a method. An experimental version of such a system achieves a median speedup of 27% for our set of SELF programs, reducing the number of non-inlined message sends by a factor of two. Implementations of dynamically-typed object-oriented languages have been limited by the paucity of type information available to the compiler. The abundance of the type information provided by PICs suggests a new compilation approach for these languages, adaptive compilation . Such compilers may succeed in generating very efficient code for the time-critical parts of a program without incurring distracting compilation pauses.",
            "author": "HÃ¶lzle, Urs and Chambers, Craig and Ungar, David",
            "booktitle": "ECOOP '91: European Conference on Object-Oriented Programming",
            "description": "Optimizing Dynamically-Typed Object-Oriented Languages With Polymorphic Inline Caches",
            "doi": "10.1007/BFb0057013",
            "isbn": "3-540-54262-0",
            "pages": "21--38",
            "publisher": "Springer",
            "series": "ECOOP'91",
            "title": "Optimizing Dynamically-Typed Object-Oriented Languages With Polymorphic Inline Caches",
            "volume": "512",
            "year": "1991",
            "url": "http://bibliography.selflanguage.org/_static/pics.pdf",
            "vm:shortTitle": "Polymorphic Inline Caches",
            "vm:edge:extends": "Deutsch:1984:IC + k-size cache"
        },
        "line": 38
    },
    {
        "citationKey": "Domani:02:TLAB",
        "entryType": "inproceedings",
        "entryTags": {
            "author": "Domani, Tamar and Goldshtein, Gal and Kolodner, Elliot K. and Lewis, Ethan and Petrank, Erez and Sheinwald, Dafna",
            "booktitle": "Proceedings of the Third International Symposium on Memory Management",
            "description": "Thread-local heaps for Java | Proceedings of the 3rd international symposium on Memory management",
            "doi": "10.1145/512429.512439",
            "keywords": "Allocation Barrier Concurrency Contention Local Threads",
            "publisher": "{ACM} Press",
            "series": "ISMM'02",
            "title": "Thread-local Heaps for Java",
            "url": "http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.63.5846&rep=rep1&type=pdf",
            "year": "2002",
            "#vm:concepts": "Tracking Reachability to Reduce Synchronization",
            "vm:shortTitle": "Thread-Local Heaps and GC"
        },
        "line": 57
    },
    {
        "citationKey": "Brunthaler:2010:EIU",
        "entryType": "inproceedings",
        "entryTags": {
            "abstract": "Just-in-time compilers offer the biggest achievable payoff performance-wise, but their implementation is a non-trivial, time-consuming task affecting the interpreter's maintenance for years to come, too. Recent research addresses this issue by providing ways of leveraging existing just-in-time compilation infrastructures.\nThough there has been considerable research on improving the efficiency of just-in-time compilers, the area of optimizing interpreters has gotten less attention as if the implementation of a dynamic translation system was the \"ultima ratio\" for efficiently interpreting programming languages. We present optimization techniques for improving the efficiency of interpreters without requiring just-in-time compilation thereby maintaining the ease-of-implementation characteristic that brought many people to implementing an interpreter in the first place.",
            "author": "Brunthaler, Stefan",
            "booktitle": "Proceedings of the 6th Symposium on Dynamic Languages",
            "doi": "10.1145/1899661.1869633",
            "issn": "0362-1340",
            "month": "oct",
            "number": "12",
            "numpages": "14",
            "pages": "1--14",
            "publisher": "ACM",
            "series": "DLS'10",
            "title": "Efficient Interpretation Using Quickening",
            "year": "2010",
            "url": "https://publications.sba-research.org/publications/dls10.pdf",
            "vm:shortTitle": "Bytecode Quickening"
        },
        "line": 73
    },
    {
        "citationKey": "Wurthinger:2012:SOAST",
        "entryType": "inproceedings",
        "entryTags": {
            "abstract": "An abstract syntax tree (AST) interpreter is a simple and natural way to implement a programming language. However, it is also considered the slowest approach because of the high overhead of virtual method dispatch. Language implementers therefore define bytecodes to speed up interpretation, at the cost of introducing inflexible and hard to maintain bytecode formats. We present a novel approach to implementing AST interpreters in which the AST is modified during interpretation to incorporate type feedback. This tree rewriting is a general and powerful mechanism to optimize many constructs common in dynamic programming languages. Our system is implemented in Java and uses the static typing and primitive data types of Java elegantly to avoid the cost of boxed representations of primitive values in dynamic programming languages.",
            "author": "WÃ¼rthinger, Thomas and WÃ¶Ã, Andreas and Stadler, Lukas and Duboscq, Gilles and Simon, Doug and Wimmer, Christian",
            "booktitle": "Proceedings of the 8th Dynamic Languages Symposium",
            "doi": "10.1145/2384577.2384587",
            "isbn": "978-1-4503-1564-7",
            "month": "October",
            "numpages": "10",
            "pages": "73--82",
            "series": "DLS'12",
            "title": "Self-Optimizing AST Interpreters",
            "url": "http://www.christianwimmer.at/Publications/Wuerthinger12a/",
            "year": "2012",
            "vm:shortTitle": "SelfOpt AST Interp.",
            "vm:edge:extends": "Brunthaler:2010:EIU + AST interpreters"
        },
        "line": 93
    },
    {
        "citationKey": "Bolz:2013:SSC",
        "entryType": "inproceedings",
        "entryTags": {
            "author": "Bolz, Carl Friedrich and Diekmann, Lukas and Tratt, Laurence",
            "booktitle": "Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages \\& Applications",
            "description": "Storage strategies for collections in dynamically typed languages",
            "doi": "10.1145/2509136.2509531",
            "isbn": "978-1-4503-2374-1",
            "numpages": "16",
            "pages": "167--182",
            "publisher": "ACM",
            "series": "OOPSLA'13",
            "title": "Storage Strategies for Collections in Dynamically Typed Languages",
            "year": "2013",
            "url": "https://tratt.net/laurie/research/pubs/html/bolz_diekmann_tratt__storage_strategies_for_collections_in_dynamically_typed_languages/",
            "vm:concepts": "Collections Representation",
            "vm:shortTitle": "Storage Strategies for Collections",
            "vm:edge:extends": "CollectionsRepresentation + adapt representation dynamically to unboxed values"
        },
        "line": 111
    },
    {
        "citationKey": "Woss:14:TOM",
        "entryType": "inproceedings",
        "entryTags": {
            "abstract": "Truffle is a Java-based framework for developing high-performance language runtimes. Language implementers aiming at developing new runtimes have to design all the runtime mechanisms for managing dynamically typed objects from scratch. This not only leads to potential code duplication, but also impacts the actual time needed to develop a fully-fledged runtime. In this paper we address this issue by introducing a common object storage model (OSM) for Truffle that can be used by language implementers to develop new runtimes. The OSM is generic, language-agnostic, and portable, as it can be used to implement a great variety of dynamic languages. It is extensible, featuring built-in support for custom extension mechanisms. It is also high-performance, as it is designed to benefit from the optimizing compiler in the Truffle framework. Our initial evaluation indicates that the Truffle OSM can be used to implement high-performance language runtimes, with no performance overhead when compared to language-specific solutions.",
            "author": "WÃ¶Ã, Andreas and Wirth, Christian and Bonetta, Daniele and Seaton, Chris and Humer, Christian and MÃ¶ssenbÃ¶ck, Hanspeter",
            "booktitle": "Proceedings of the 2014 International Conference on Principles and Practices of Programming on the Java Platform: Virtual Machines, Languages, and Tools",
            "doi": "10.1145/2647508.2647517",
            "isbn": "978-1-4503-2926-2",
            "numpages": "12",
            "pages": "133--144",
            "publisher": "ACM",
            "series": "PPPJ'14",
            "title": "An Object Storage Model for the Truffle Language Implementation Framework",
            "year": "2014",
            "url": "https://chrisseaton.com/rubytruffle/pppj14-om/pppj14-om.pdf",
            "vm:shortTitle": "Truffle Object Model",
            "vm:edge:extends": "Chambers:89:Self + unboxed values, read-only & type specialization"
        },
        "line": 130
    },
    {
        "citationKey": "Marr:15:DC",
        "entryType": "inproceedings",
        "entryTags": {
            "abstract": "Runtime metaprogramming enables many useful applications and is often a convenient solution to solve problems in a generic way, which makes it widely used in frameworks, middleware, and domain-specific languages. However, powerful metaobject protocols are rarely supported and even common concepts such as reflective method invocation or dynamic proxies are not optimized. Solutions proposed in literature either restrict the metaprogramming capabilities or require application or library developers to apply performance improving techniques.\nFor overhead-free runtime metaprogramming, we demonstrate that dispatch chains, a generalized form of polymorphic inline caches common to self-optimizing interpreters, are a simple optimization at the language-implementation level. Our evaluation with self-optimizing interpreters shows that unrestricted metaobject protocols can be realized for the first time without runtime overhead, and that this optimization is applicable for just-in-time compilation of interpreters based on meta-tracing as well as partial evaluation. In this context, we also demonstrate that optimizing common reflective operations can lead to significant performance improvements for existing applications.",
            "appendix": "https://stefan-marr.de/papers/pldi-marr-et-al-zero-overhead-metaprogramming-artifacts/",
            "author": "Marr, Stefan and Seaton, Chris and Ducasse, StÃ©phane",
            "blog": "https://stefan-marr.de/2015/04/zero-overhead-metaprogramming/",
            "booktitle": "Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation",
            "doi": "10.1145/2737924.2737963",
            "html": "https://stefan-marr.de/papers/pldi-marr-et-al-zero-overhead-metaprogramming/",
            "isbn": "978-1-4503-3468-6",
            "month": "June",
            "numpages": "10",
            "pages": "545--554",
            "url": "https://stefan-marr.de/downloads/pldi15-marr-et-al-zero-overhead-metaprogramming.pdf",
            "publisher": "ACM",
            "series": "PLDI'15",
            "title": "Zero-Overhead Metaprogramming: Reflection and Metaobject Protocols Fast and without Compromises",
            "year": "2015",
            "vm:shortTitle": "Dispatch Chains (Multidimensional Lookup Caches)",
            "vm:edge:uses": "Wurthinger:2012:SOAST",
            "vm:edge:extends": "Hoelzle:91:PIC + nested PICs, cache for metaprogramming"
        },
        "line": 149
    },
    {
        "citationKey": "Daloze:2015:GLS",
        "entryType": "inproceedings",
        "entryTags": {
            "abstract": "Safepoints are a virtual machine mechanism that allows one thread\nto suspend other threads in a known state so that runtime actions\ncan be performed without interruption and with data structures in a\nconsistent state. Many virtual machines use safepoints as a mechanism\nto provide services such as stop-the-world garbage collection,\ndebugging, and modification to running code such as installing\nor replacing classes. Languages implemented on these virtual machines\nmay have access to these services, but not directly to the\nsafepoint mechanism itself. We show that safepoints have many\nuseful applications for the implementation of guest languages running\non a virtual machine. We describe an API for using safepoints\nin languages that were implemented under the Truffle language implementation\nframework on the Java Virtual Machine and show\nseveral applications of the API to implement useful guest-language\nfunctionality. We present an efficient implementation of this API,\nwhen running in combination with the Graal dynamic compiler. We\nalso demonstrate that our safepoints cause zero overhead with respect\nto peak performance and statistically insignificant overhead\nwith respect to compilation time. We compare this to other techniques\nthat could be used to implement the same functionality and\ndemonstrate the large overhead that they incur.",
            "author": "Daloze, Benoit and Seaton, Chris and Bonetta, Daniele and MÃ¶ssenbÃ¶ck, Hanspeter",
            "booktitle": "Proceedings of the 10th International Workshop on Implementation, Compilation, Optimization of Object-Oriented Languages, Programs and Systems",
            "numpages": "10",
            "series": "ICOOOLPS'15",
            "title": "Techniques and Applications for Guest-Language Safepoints",
            "year": "2015",
            "url": "https://eregon.me/blog/assets/research/guest-language-safepoints.pdf",
            "vm:shortTitle": "Guest-Language Safepoints"
        },
        "line": 173
    },
    {
        "citationKey": "Daloze:2016:TSO",
        "entryType": "inproceedings",
        "entryTags": {
            "abstract": "We are in the multi-core era.\nDynamically-typed languages are in widespread use, but their support for\nmultithreading still lags behind. One of the reasons is that the sophisticated\ntechniques they use to efficiently represent their dynamic object models are\noften unsafe in multithreaded environments.\n\nThis paper defines safety requirements for dynamic object models in\nmultithreaded environments.\nBased on these requirements, a language-agnostic and thread-safe object model\nis designed that maintains the efficiency of sequential approaches.\nThis is achieved by ensuring that field reads do not require synchronization\nand field updates only need to synchronize on objects shared between threads.\n\nBasing our work on JRuby+Truffle, we show that our safe object model has zero overhead on peak performance for thread-local objects\nand only 3\\% average overhead on parallel benchmarks where field updates require synchronization.\nThus, it can be a foundation for safe and efficient multithreaded VMs for a wide range of dynamic languages.",
            "author": "Daloze, Benoit and Marr, Stefan and Bonetta, Daniele and MÃ¶ssenbÃ¶ck, Hanspeter",
            "booktitle": "Proceedings of the 2016 ACM International Conference on Object Oriented Programming Systems Languages \\& Applications",
            "day": "2",
            "doi": "10.1145/2983990.2984001",
            "isbn": "978-1-4503-4444-9",
            "month": "November",
            "numpages": "18",
            "pages": "642--659",
            "url": "https://eregon.me/blog/assets/research/thread-safe-objects.pdf",
            "publisher": "ACM",
            "series": "OOPSLA'16",
            "title": "Efficient and Thread-Safe Objects for Dynamically-Typed Languages",
            "year": "2016",
            "vm:shortTitle": "Thread-Safe Object Model",
            "vm:edge:extends": "Domani:02:TLAB + self-specializing write barrier;\n    Woss:14:TOM + thread safety",
            "vm:edge:uses": "Marr:15:DC for efficient sharing"
        },
        "line": 206
    },
    {
        "citationKey": "Ungar:17:DA",
        "entryType": "inproceedings",
        "entryTags": {
            "author": "Ungar, David and Grove, David and Franke, Hubertus",
            "booktitle": "Proceedings of the 13th {ACM} {SIGPLAN} International Symposium on on Dynamic Languages  - {DLS} 2017",
            "description": "Dynamic atomicity: optimizing swift memory management | Proceedings of the 13th ACM SIGPLAN International Symposium on on Dynamic Languages",
            "doi": "10.1145/3133841.3133843",
            "keywords": "MemoryManagement Reachability ReferenceCounting Swift",
            "publisher": "{ACM} Press",
            "series": "DLS'17",
            "title": "Dynamic Atomicity: Optimizing Swift Memory Management",
            "url": "https://doi.org/10.1145/3133841.3133843",
            "year": "2017",
            "vm:shortTitle": "Reachability for Dynamic Atomic Reference Counting",
            "vm:edge:extends": "Daloze:2016:TSO + eliminate local refcounting"
        },
        "line": 245
    },
    {
        "citationKey": "Daloze:2018:TSC",
        "entryType": "article",
        "entryTags": {
            "abstract": "Dynamic programming languages such as Python and Ruby are widely used, and much effort is spent on making them efficient. One substantial research effort in this direction is the enabling of parallel code execution. While there has been significant progress, making dynamic collections efficient, scalable, and thread-safe is an open issue. Typical programs in dynamic languages use few but versatile collection types. Such collections are an important ingredient of dynamic environments, but are difficult to make safe, efficient, and scalable.\n              In this paper, we propose an approach for efficient and concurrent collections by gradually increasing synchronization levels according to the dynamic needs of each collection instance. Collections reachable only by a single thread have no synchronization, arrays accessed in bounds have minimal synchronization, and for the general case, we adopt the Layout Lock paradigm and extend its design with a lightweight version that fits the setting of dynamic languages. We apply our approach to Rubyâs Array and Hash collections. Our experiments show that our approach has no overhead on single-threaded benchmarks, scales linearly for Array and Hash accesses, achieves the same scalability as Fortran and Java for classic parallel algorithms, and scales better than other Ruby implementations on Ruby workloads.",
            "author": "Daloze, Benoit and Tal, Arie and Marr, Stefan and MÃ¶ssenbÃ¶ck, Hanspeter and Petrank, Erez",
            "doi": "10.1145/3276478",
            "journal": "Proceedings of the ACM on Programming Languages",
            "month": "November",
            "number": "OOPSLA",
            "pages": "108:1--108:30",
            "url": "https://eregon.me/blog/assets/research/thread-safe-collections.pdf",
            "series": "OOPSLA'18",
            "title": "Parallelization of Dynamic Languages: Synchronizing Built-in Collections",
            "volume": "2",
            "year": "2018",
            "vm:shortTitle": "Synchronize Collections based on Reachability",
            "vm:edge:extends": "Bolz:2013:SSC + thread safety;\n    Daloze:2016:TSO + collections",
            "vm:edge:uses": "Daloze:2015:GLS"
        },
        "line": 261
    },
    {
        "citationKey": "Choi:18:BRC",
        "entryType": "inproceedings",
        "entryTags": {
            "author": "Choi, Jiho and Shull, Thomas and Torrellas, Josep",
            "booktitle": "Proceedings of the 27th International Conference on Parallel Architectures and Compilation Techniques",
            "doi": "10.1145/3243176.3243195",
            "publisher": "{ACM} Press",
            "series": "PACT'18",
            "title": "Biased Reference Counting",
            "url": "https://iacoma.cs.uiuc.edu/iacoma-papers/pact18.pdf",
            "year": "2018",
            "vm:shortTitle": "Biased Reference Counting",
            "vm:edge:similar": "Ungar:17:DA similar with bias towards a thread"
        },
        "line": 284
    }
]