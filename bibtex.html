<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <script src="https://d3js.org/d3.v5.min.js"></script>
  <script src="https://unpkg.com/@hpcc-js/wasm@0.3.6/dist/index.min.js"></script>
  <script src="https://unpkg.com/d3-graphviz@3.0.0/build/d3-graphviz.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/bibtex-parse-js@0.0.24/bibtexParse.js" integrity="sha256-v968ksKZppVegXgenPlIK/9mN80zJo1PXOCu+ao0lKw=" crossorigin="anonymous"></script>
</head>

<body>
  <h1>
    Virtual Machine Research Overview
  </h1>

  <p>
    <strong>Disclaimer:</strong> It's not assumed this overview is complete in any way.
  </p>
  <p>
  <a href="https://github.com/eregon/virtual-machines-research-graph/edit/master/graph.dot">Edit on GitHub</a>
  </p>
<div id="graph" style="text-align: center;"></div>
<script>
//@ts-check
'use strict';

function getPapersAndConcepts(entries) {
  const papers = [];
  const concepts = {};

  for (const paper of entries) {
    const p = {
      id: paper.citationKey,
      shortTitle: paper.entryTags['vm:shortTitle'],
      venue: paper.entryTags.series,
      title: paper.entryTags.title,
      url: paper.entryTags.url,
      year: paper.entryTags.year
    };

    // check completeness
    for (const [key, value] of Object.entries(p)) {
      if (!value) {
        console.warn(`${paper.citationKey} misses ${key}`);
      }
    }

    // extract concepts
    if (paper.entryTags['vm:concepts']) {
      const cs = paper.entryTags['vm:concepts'].split(',');
      for (const c of cs) {
        if (c.trim().length > 0) {
          const concept = {
            id: getConceptId(c),
            name: c.trim()
          };

          concepts[concept.id] = concept;
          if (!p.concepts) {
            p.concepts = [];
          }
          p.concepts.push(concept);

          if (!p.edges) {
            p.edges = [];
          }
          p.edges.push({
            type: 'concept',
            target: concept.id,
            label: null
          });
        }
      }
    }

    // extract edges
    for (const key of Object.keys(paper.entryTags)) {
      if (key.startsWith('vm:edge:')) {
        const edgeName = key.replace('vm:edge:', '');
        const edges = paper.entryTags[key].split(';');

        for (const e of edges) {
          const trimmed = e.trim();
          const idxFirstSpace = trimmed.indexOf(' ');
          const targetId = idxFirstSpace === -1 ? trimmed : trimmed.substr(0, idxFirstSpace);
          let label = idxFirstSpace === -1 ? null : trimmed.substr(idxFirstSpace).trim();
          if (label && label.length == 0) {
            label = null;
          }

          if (!p.edges) {
            p.edges = [];
          }
          p.edges.push({
            type: edgeName,
            target: targetId,
            label: label
          });
        }
      }
    }

    papers.push(p);
  }
  return {papers, concepts};
}

function getConceptId(str) {
  return str.trim().replace(/\s/g,'');
}

function renderConcepts(concepts) {
  let result = '';
  for (const c of Object.values(concepts)) {
    result += `
      "${c.id}" [
        label = "${c.name}",
        shape = "oval"
      ]
    `;
  }
  return result;
}

function renderPapers(papers) {
  let result = '';
  for (const paper of papers) {
    result += `
      "${paper.id}" [
        label = "${paper.shortTitle} (${paper.venue})",
        tooltip = "${paper.title}",
        URL = "${paper.url}"
      ]
    `;
  }

  return result;
}

function renderEdges(papers) {
  const edgeTypes = {
    'default': 'solid',
    'concept': 'dotted',
    'extends': 'solid',
    'uses':    'dashed'
  };
  let result = '';
  for (const paper of papers) {
    if (!paper.edges) {
      continue;
    }

    for (const edge of paper.edges) {
      let style = edgeTypes[edge.type];
      if (!style) {
        style = edgeTypes['default'];
      }

      let label = '';
      if (edge.label) {
        label = `label = "${edge.label}",`
      }

      result += `
        "${edge.target}" -> "${paper.id}" [
          ${label}
          style = "${style}"
        ]
        `;
    }
  }
  return result;
}

function renderToDot(papers, concepts) {
  let result = `digraph G {
  node [shape = "box"]`;

  result += renderConcepts(concepts);
  result += renderPapers(papers);
  result += renderEdges(papers);

  result += '}';
  return result;
}

function convertToDot(bibtex) {
  const entries = bibtexParse.toJSON(bibtex);
  const {papers, concepts} = getPapersAndConcepts(entries);
  return renderToDot(papers, concepts);
}


// const dataPromise = fetch('https://raw.githubusercontent.com/eregon/virtual-machines-research-graph/master/vm.bib')
//   .then((response) => {
//     return response.text();
//   });
const dataPromise = new Promise((resolve) => {
  resolve(convertToDot(`
  @inproceedings{Deutsch:1984:IC,
  abstract = {The Smalltalk-80* programming language includes dynamic storage allocation, full upward funargs, and universally polymorphic procedures; the Smalltalk-80 programming system features interactive execution with incremental compilation, and implementation portability. These features of modern programming systems are among the most difficult to implement efficiently, even individually. A new implementation of the Smalltalk-80 system, hosted on a small microprocessor-based computer, achieves high performance while retaining complete (object code) compatibility with existing implementations. This paper discusses the most significant optimization techniques developed over the course of the project, many of which are applicable to other languages. The key idea is to represent certain runtime state (both code and data) in more than one form, and to convert between forms when needed.},
  author = {Deutsch, L. Peter and Schiffman, Allan M.},
  booktitle = {POPL '84: Proceedings of the 11th ACM SIGACT-SIGPLAN symposium on Principles of programming languages},
  description = {Efficient Implementation of the Smalltalk-80 System},
  doi = {10.1145/800017.800542},
  isbn = {0-89791-125-3},
  pages = {297--302},
  publisher = {ACM},
  series = {POPL'84},
  title = {Efficient Implementation of the Smalltalk-80 System},
  year = 1984,
  url = "http://web.cs.ucla.edu/~palsberg/course/cs232/papers/DeutschSchiffman-popl84.pdf",

  vm:concepts = {Lookup Caches, Execution},
  vm:shortTitle = {Inline Caches}
}

@inproceedings{Chambers:89:Self,
  abstract = {We have developed and implemented techniques that double the performance of dynamically-typed object-oriented languages. Our SELF implementation runs twice as fast as the fastest Smalltalk implementation, despite SELF's lack of classes and explicit variables. To compensate for the absence of classes, our system uses implementation-level maps to transparently group objects cloned from the same prototype, providing data type information and eliminating the apparent space overhead for prototype-based systems. To compensate for dynamic typing, user-defined control structures, and the lack of explicit variables, our system dynamically compiles multiple versions of a source method, each customized according to its receiver's map. Within each version the type of the receiver is fixed, and thus the compiler can statically bind and inline all messages sent to self. Message splitting and type prediction extract and preserve even more static type information, allowing the compiler to inline many other messages. Inlining dramatically improves performance and eliminates the need to hard-wire low-level methods such as +,==, and ifTrue:. Despite inlining and other optimizations, our system still supports interactive programming environments. The system traverses internal dependency lists to invalidate all compiled methods affected by a programming change. The debugger reconstructs inlined stack frames from compiler-generated debugging information, making inlining invisible to the SELF programmer.},
  author = {Chambers, Craig and Ungar, David and Lee, Elgin},
  booktitle = {Proceedings on Object-Oriented Programming Systems, Languages and Applications},
  doi = {10.1145/74878.74884},
  isbn = {0-89791-333-7},
  issn = {0362-1340},
  month = {October},
  pages = {49--70},
  publisher = {ACM},
  series = {OOPSLA'89},
  title = {An Efficient Implementation of SELF a Dynamically-Typed Object-Oriented Language Based on Prototypes},
  year = 1989,
  url = {http://www.selflanguage.org/_static/published/implementation.pdf},

  vm:concepts = {Object Representation},
  vm:shortTitle = {SELF & Maps},
  vm:edge:uses = {Deutsch:1984:IC + compilation}
}

@inproceedings{Hoelzle:91:PIC,
  abstract = {Polymorphic inline caches (PICs) provide a new way to reduce the overhead of polymorphic message sends by extending inline caches to include more than one cached lookup result per call site. For a set of typical object-oriented SELF programs, PICs achieve a median speedup of 11%. As an important side effect, PICs collect type information by recording all of the receiver types actually used at a given call site. The compiler can exploit this type information to generate better code when recompiling a method. An experimental version of such a system achieves a median speedup of 27% for our set of SELF programs, reducing the number of non-inlined message sends by a factor of two. Implementations of dynamically-typed object-oriented languages have been limited by the paucity of type information available to the compiler. The abundance of the type information provided by PICs suggests a new compilation approach for these languages, adaptive compilation . Such compilers may succeed in generating very efficient code for the time-critical parts of a program without incurring distracting compilation pauses.},
  author = {HÃ¶lzle, Urs and Chambers, Craig and Ungar, David},
  booktitle = {ECOOP '91: European Conference on Object-Oriented Programming},
  description = {Optimizing Dynamically-Typed Object-Oriented Languages With Polymorphic Inline Caches},
  doi = {10.1007/BFb0057013},
  isbn = {3-540-54262-0},
  pages = {21--38},
  publisher = {Springer},
  series = {ECOOP'91},
  title = {Optimizing Dynamically-Typed Object-Oriented Languages With Polymorphic Inline Caches},
  volume = 512,
  year = 1991,
  url = {http://bibliography.selflanguage.org/_static/pics.pdf},

  vm:concepts = {Lookup Caches},
  vm:shortTitle = {Polymorphic Inline Caches},
  vm:edge:extends = {Deutsch:1984:IC + k-size cache}
}

@inproceedings{Ertl:1995:Stack,
  abstract = {An interpreter can spend a significant part of its execution time on accessing arguments of virtual machine instructions. This paper explores two methods to reduce this overhead for virtual stack machines by caching top-of-stack values in (real machine) registers. The dynamic method is based on having, for every possible state of the cache, one specialized version of the whole interpreter; the execution of an instruction usually changes the state of the cache and the next instruction is executed in the version corresponding to the new state. In the static method a state machine that keeps track of the cache state is added to the compiler. Common instructions exist in specialized versions for several states, but it is not necessary to have a version of every instruction for every cache state. Stack manipulation instructions are optimized away.},
  author = {Ertl, M. Anton},
  booktitle = {Proceedings of the ACM SIGPLAN 1995 Conference on Programming Language Design and Implementation},
  doi = {10.1145/207110.207165},
  issn = {0362-1340},
  pages = {315--327},
  publisher = {ACM},
  series = {PLDI'95},
  title = {Stack Caching for Interpreters},
  url = {http://www.complang.tuwien.ac.at/papers/ertl95pldi.ps.gz},
  year = 1995,

  vm:concepts = {Interpretation},
  vm:shortTitle = {Top of Stack Caching},
  vm:edge:extends = {Interpretation + optimization}
}

@inproceedings{Domani:02:TLAB,
  author = {Domani, Tamar and Goldshtein, Gal and Kolodner, Elliot K. and Lewis, Ethan and Petrank, Erez and Sheinwald, Dafna},
  booktitle = {Proceedings of the third international symposium on Memory management  - {ISMM} {\textquotesingle}02},
  description = {Thread-local heaps for Java | Proceedings of the 3rd international symposium on Memory management},
  doi = {10.1145/512429.512439},
  keywords = {Allocation Barrier Concurrency Contention Local Threads},
  publisher = {{ACM} Press},
  series = {ISMM'02},
  title = {Thread-local Heaps for Java},
  url = {https://doi.org/10.114/512429.512439},
  year = 2002,

  vm:concepts = {
    Garbage Collection,
    Tracking Reachability to Reduce Synchronization},
  vm:shortTitle = {Thread-Local Heaps and GC}
}

@article{Shi:2008:SVR,
  author = {Shi, Yunhe and Casey, Kevin and Ertl, M. Anton and Gregg, David},
  doi = {10.1145/1328195.1328197},
  issn = {1544-3566},
  journal = {ACM Trans. Archit. Code Optim.},
  number = 4,
  pages = {1--36},
  publisher = {ACM},
  title = {Virtual Machine Showdown: Stack Versus Registers},
  url = {https://doi.org/10.1145/1328195.1328197},
  volume = 4,
  year = 2008,

  vm:concepts = {Interpretation},
  vm:shortTitle = {Stack vs. Register}
}



@inproceedings{Bolz:2013:SSC,
  author = {Bolz, Carl Friedrich and Diekmann, Lukas and Tratt, Laurence},
  booktitle = {Proceedings of the 2013 ACM SIGPLAN International Conference on Object Oriented Programming Systems Languages \& Applications},
  description = {Storage strategies for collections in dynamically typed languages},
  doi = {10.1145/2509136.2509531},
  isbn = {978-1-4503-2374-1},
  numpages = {16},
  pages = {167--182},
  publisher = {ACM},
  series = {OOPSLA'13},
  title = {Storage Strategies for Collections in Dynamically Typed Languages},
  year = 2013,
  url = "https://tratt.net/laurie/research/pubs/html/bolz_diekmann_tratt__storage_strategies_for_collections_in_dynamically_typed_languages/",

  vm:concepts = {Collections Representation},
  vm:shortTitle = {Storage Strategies for Collections},
  vm:edge:extends = {CollectionsRepresentation + adapt representation dynamically to unboxed values}
}

@inproceedings{Woss:14:TOM,
  abstract = {Truffle is a Java-based framework for developing high-performance language runtimes. Language implementers aiming at developing new runtimes have to design all the runtime mechanisms for managing dynamically typed objects from scratch. This not only leads to potential code duplication, but also impacts the actual time needed to develop a fully-fledged runtime. In this paper we address this issue by introducing a common object storage model (OSM) for Truffle that can be used by language implementers to develop new runtimes. The OSM is generic, language-agnostic, and portable, as it can be used to implement a great variety of dynamic languages. It is extensible, featuring built-in support for custom extension mechanisms. It is also high-performance, as it is designed to benefit from the optimizing compiler in the Truffle framework. Our initial evaluation indicates that the Truffle OSM can be used to implement high-performance language runtimes, with no performance overhead when compared to language-specific solutions.},
  author = {WÃ¶Ã, Andreas and Wirth, Christian and Bonetta, Daniele and Seaton, Chris and Humer, Christian and MÃ¶ssenbÃ¶ck, Hanspeter},
  booktitle = {Proceedings of the 2014 International Conference on Principles and Practices of Programming on the Java Platform: Virtual Machines, Languages, and Tools},
  doi = {10.1145/2647508.2647517},
  isbn = {978-1-4503-2926-2},
  numpages = {12},
  pages = {133--144},
  publisher = {ACM},
  series = {PPPJ'14},
  title = {An Object Storage Model for the Truffle Language Implementation Framework},
  year = 2014,
  url = "https://chrisseaton.com/rubytruffle/pppj14-om/pppj14-om.pdf",

  vm:shortTitle = {Truffle Object Model},
  vm:edge:extends = {
    Chambers:89:Self + unboxed values, read-only & type specialization;
    ObjectRepresentation + efficient access and lower memory footprint}
}

@inproceedings{Marr:15:DC,
  abstract = {Runtime metaprogramming enables many useful applications and is often a convenient solution to solve problems in a generic way, which makes it widely used in frameworks, middleware, and domain-specific languages. However, powerful metaobject protocols are rarely supported and even common concepts such as reflective method invocation or dynamic proxies are not optimized. Solutions proposed in literature either restrict the metaprogramming capabilities or require application or library developers to apply performance improving techniques.
For overhead-free runtime metaprogramming, we demonstrate that dispatch chains, a generalized form of polymorphic inline caches common to self-optimizing interpreters, are a simple optimization at the language-implementation level. Our evaluation with self-optimizing interpreters shows that unrestricted metaobject protocols can be realized for the first time without runtime overhead, and that this optimization is applicable for just-in-time compilation of interpreters based on meta-tracing as well as partial evaluation. In this context, we also demonstrate that optimizing common reflective operations can lead to significant performance improvements for existing applications.},
  appendix = {https://stefan-marr.de/papers/pldi-marr-et-al-zero-overhead-metaprogramming-artifacts/},
  author = {Marr, Stefan and Seaton, Chris and Ducasse, StÃ©phane},
  blog = {https://stefan-marr.de/2015/04/zero-overhead-metaprogramming/},
  booktitle = {Proceedings of the 36th ACM SIGPLAN Conference on Programming Language Design and Implementation},
  doi = {10.1145/2737924.2737963},
  html = {https://stefan-marr.de/papers/pldi-marr-et-al-zero-overhead-metaprogramming/},
  isbn = {978-1-4503-3468-6},
  month = {June},
  numpages = {10},
  pages = {545--554},
  url = {https://stefan-marr.de/downloads/pldi15-marr-et-al-zero-overhead-metaprogramming.pdf},
  publisher = {ACM},
  series = {PLDI'15},
  title = {Zero-Overhead Metaprogramming: Reflection and Metaobject Protocols Fast and without Compromises},
  year = 2015,

  vm:concepts = {Lookup Caches, Metaobject Protocols},
  vm:shortTitle = {Dispatch Chains (Multidimensional Lookup Caches)},
  vm:edge:extends = {Hoelzle:91:PIC + nested PICs, cache for metaprogramming}
}

@inproceedings{Daloze:2015:GLS,
  abstract = {Safepoints are a virtual machine mechanism that allows one thread
to suspend other threads in a known state so that runtime actions
can be performed without interruption and with data structures in a
consistent state. Many virtual machines use safepoints as a mechanism
to provide services such as stop-the-world garbage collection,
debugging, and modification to running code such as installing
or replacing classes. Languages implemented on these virtual machines
may have access to these services, but not directly to the
safepoint mechanism itself. We show that safepoints have many
useful applications for the implementation of guest languages running
on a virtual machine. We describe an API for using safepoints
in languages that were implemented under the Truffle language implementation
framework on the Java Virtual Machine and show
several applications of the API to implement useful guest-language
functionality. We present an efficient implementation of this API,
when running in combination with the Graal dynamic compiler. We
also demonstrate that our safepoints cause zero overhead with respect
to peak performance and statistically insignificant overhead
with respect to compilation time. We compare this to other techniques
that could be used to implement the same functionality and
demonstrate the large overhead that they incur.},
  author = {Daloze, Benoit and Seaton, Chris and Bonetta, Daniele and MÃ¶ssenbÃ¶ck, Hanspeter},
  booktitle = {Proceedings of the 10th International Workshop on Implementation, Compilation, Optimization of Object-Oriented Languages, Programs and Systems},
  numpages = {10},
  series = {ICOOOLPS'15},
  title = {Techniques and Applications for Guest-Language Safepoints},
  year = 2015,
  url = "https://eregon.me/blog/assets/research/guest-language-safepoints.pdf",

  vm:concepts = {Safepoints},
  vm:shortTitle = {Guest-Language Safepoints}
}

@inproceedings{Pape:2015:LSS,
  abstract = {Storage strategies have been proposed as a run-time optimization for the PyPy Python implementation and have shown promising results for optimizing execution speed and memory requirements. However, it remained unclear whether the approach works equally well in other dynamic languages. Furthermore, while PyPy is based on RPython, a language to write VMs with reusable components such as a tracing just-in-time compiler and garbage collection, the strategies design itself was not generalized to be reusable across languages implemented using that same toolchain. In this paper, we present a general design and implementation for storage strategies and show how they can be reused across different RPython-based languages. We evaluate the performance of our implementation for RSqueak, an RPython-based VM for Squeak/Smalltalk and show that storage strategies may indeed offer performance benefits for certain workloads in other dynamic programming languages.We furthermore evaluate the generality of our implementation by applying it to Topaz, a Ruby VM, and Pycket, a Racket implementation.},
  author = {Pape, Tobias and Felgentreff, Tim and Hirschfeld, Robert and Gulenko, Anton and Bolz, Carl Friedrich},
  booktitle = {Proceedings of the 11th Symposium on Dynamic Languages},
  doi = {10.1145/2816707.2816716},
  isbn = {978-1-4503-3690-1},
  numpages = {10},
  pages = {104--113},
  publisher = {ACM},
  series = {DLS'15},
  title = {Language-independent Storage Strategies for tracing-JIT-based Virtual Machines},
  year = 2015,
  url = "https://www.hpi.uni-potsdam.de/hirschfeld/publications/media/PapeFelgentreffHirschfeldGulenkoBolz_2015_LanguageIndependentStorageStrategiesForTracingJitBasedVirtualMachines_AuthorsVersion.pdf",

  vm:shortTitle = {Language-independent Storage Strategies},
  vm:edge:extends = {Bolz:2013:SSC + language independent}
}

@inproceedings{Chevalier-Boisvert:2016:ITS,
  author = {Chevalier-Boisvert, Maxime and Feeley, Marc},
  booktitle = {30th European Conference on Object-Oriented Programming (ECOOP 2016)},
  description = {DROPS - Interprocedural Type Specialization of JavaScript Programs Without Type Analysis},
  doi = {10.4230/LIPIcs.ECOOP.2016.7},
  isbn = {978-3-95977-014-9},
  issn = {1868-8969},
  pages = {7:1--7:24},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  series = {ECOOP'16},
  title = {Interprocedural Type Specialization of JavaScript Programs Without Type Analysis},
  volume = 56,
  year = 2016,
  url = "https://drops.dagstuhl.de/opus/volltexte/2016/6101/pdf/LIPIcs-ECOOP-2016-7.pdf",

  vm:shortTitle = {Shapes and Basic Block Versioning},
  vm:edge:extends = {Woss:14:TOM + basic block versioning}
}


@inproceedings{Daloze:2016:TSO,
  abstract = {We are in the multi-core era.
Dynamically-typed languages are in widespread use, but their support for
multithreading still lags behind. One of the reasons is that the sophisticated
techniques they use to efficiently represent their dynamic object models are
often unsafe in multithreaded environments.

This paper defines safety requirements for dynamic object models in
multithreaded environments.
Based on these requirements, a language-agnostic and thread-safe object model
is designed that maintains the efficiency of sequential approaches.
This is achieved by ensuring that field reads do not require synchronization
and field updates only need to synchronize on objects shared between threads.

Basing our work on JRuby+Truffle, we show that our safe object model has zero overhead on peak performance for thread-local objects
and only 3\% average overhead on parallel benchmarks where field updates require synchronization.
Thus, it can be a foundation for safe and efficient multithreaded VMs for a wide range of dynamic languages.},
  author = {Daloze, Benoit and Marr, Stefan and Bonetta, Daniele and MÃ¶ssenbÃ¶ck, Hanspeter},
  booktitle = {Proceedings of the 2016 ACM International Conference on Object Oriented Programming Systems Languages \& Applications},
  day = 2,
  doi = {10.1145/2983990.2984001},
  isbn = {978-1-4503-4444-9},
  month = {November},
  numpages = {18},
  pages = {642--659},
  url = {https://eregon.me/blog/assets/research/thread-safe-objects.pdf},
  publisher = {ACM},
  series = {OOPSLA'16},
  title = {Efficient and Thread-Safe Objects for Dynamically-Typed Languages},
  year = 2016,

  vm:concepts = {VM Implementation Thread Safety},
  vm:shortTitle = {Thread-Safe Object Model},
  vm:edge:extends = {
    Domani:02:TLAB + self-specializing write barrier;
    Marr:15:DC for efficient sharing;
    Woss:14:TOM + thread safety}
}

@inproceedings{Marr:2016:AWFY,
  abstract = {Comparing the performance of programming languages is difficult because they differ in many aspects including preferred programming abstractions, available frameworks, and their runtime systems. Nonetheless, the question about relative performance comes up repeatedly in the research community, industry, and wider audience of enthusiasts.
This paper presents 14 benchmarks and a novel methodology to assess the compiler effectiveness across language implementations. Using a set of common language abstractions, the benchmarks are implemented in Java, JavaScript, Ruby, Crystal, Newspeak, and Smalltalk. We show that the benchmarks exhibit a wide range of characteristics using language-agnostic metrics. Using four different languages on top of the same compiler, we show that the benchmarks perform similarly and therefore allow for a comparison of compiler effectiveness across languages. Based on anecdotes, we argue that these benchmarks help language implementers to identify performance bugs and optimization potential by comparing to other language implementations.},
  appendix = {https://github.com/smarr/are-we-fast-yet#readme},
  author = {Marr, Stefan and Daloze, Benoit and MÃ¶ssenbÃ¶ck, Hanspeter},
  blog = {http://stefan-marr.de/2016/10/cross-language-compiler-benchmarking-are-we-fast-yet/},
  booktitle = {Proceedings of the 12th Symposium on Dynamic Languages},
  day = 1,
  doi = {10.1145/2989225.2989232},
  html = {http://stefan-marr.de/papers/dls-marr-et-al-cross-language-compiler-benchmarking-are-we-fast-yet/},
  isbn = {978-1-4503-4445-6},
  month = {November},
  numpages = {12},
  pages = {120--131},
  url = {https://stefan-marr.de/downloads/dls16-marr-et-al-cross-language-compiler-benchmarking-are-we-fast-yet.pdf},
  publisher = {ACM},
  series = {DLS'16},
  title = {Cross-Language Compiler Benchmarking---Are We Fast Yet?},
  year = 2016,

  vm:concepts = {Benchmarking},
  vm:shortTitle = {Are We Fast Yet? Benchmarks}
}

@inproceedings{Ungar:17:DA,
  author = {Ungar, David and Grove, David and Franke, Hubertus},
  booktitle = {Proceedings of the 13th {ACM} {SIGPLAN} International Symposium on on Dynamic Languages  - {DLS} 2017},
  description = {Dynamic atomicity: optimizing swift memory management | Proceedings of the 13th ACM SIGPLAN International Symposium on on Dynamic Languages},
  doi = {10.1145/3133841.3133843},
  keywords = {MemoryManagement Reachability ReferenceCounting Swift},
  publisher = {{ACM} Press},
  series = {DLS'17},
  title = {Dynamic Atomicity: Optimizing Swift Memory Management},
  url = {https://doi.org/10.1145%2F3133841.3133843},
  year = 2017,

  vm:concepts = {Garbage Collection},
  vm:shortTitle = {Reachability for Dynamic Atomic Reference Counting},
  vm:edge:extends = {Daloze:2016:TSO + eliminate local refcounting}
}

@article{Daloze:2018:TSC,
  abstract = {Dynamic programming languages such as Python and Ruby are widely used, and much effort is spent on making them efficient. One substantial research effort in this direction is the enabling of parallel code execution. While there has been significant progress, making dynamic collections efficient, scalable, and thread-safe is an open issue. Typical programs in dynamic languages use few but versatile collection types. Such collections are an important ingredient of dynamic environments, but are difficult to make safe, efficient, and scalable.
              In this paper, we propose an approach for efficient and concurrent collections by gradually increasing synchronization levels according to the dynamic needs of each collection instance. Collections reachable only by a single thread have no synchronization, arrays accessed in bounds have minimal synchronization, and for the general case, we adopt the Layout Lock paradigm and extend its design with a lightweight version that fits the setting of dynamic languages. We apply our approach to Rubyâs Array and Hash collections. Our experiments show that our approach has no overhead on single-threaded benchmarks, scales linearly for Array and Hash accesses, achieves the same scalability as Fortran and Java for classic parallel algorithms, and scales better than other Ruby implementations on Ruby workloads.},
  author = {Daloze, Benoit and Tal, Arie and Marr, Stefan and MÃ¶ssenbÃ¶ck, Hanspeter and Petrank, Erez},
  doi = {10.1145/3276478},
  journal = {Proceedings of the ACM on Programming Languages},
  month = {November},
  number = {OOPSLA},
  pages = {108:1--108:30},
  url = {https://eregon.me/blog/assets/research/thread-safe-collections.pdf},
  series = {OOPSLA'18},
  title = {{Parallelization of Dynamic Languages: Synchronizing Built-in Collections}},
  volume = 2,
  year = 2018,

  vm:shortTitle = {Synchronizing Collections based on Reachability},
  vm:edge:extends = {
    Bolz:2013:SSC + thread safety;
    Daloze:2016:TSO + collections},
  vm:edge:uses = {
    Daloze:2015:GLS + global synchronization;
    Daloze:2016:TSO + tracking reachability}
}

@inproceedings{Choi:18:BRC,
  author = {Choi, Jiho and Shull, Thomas and Torrellas, Josep},
  booktitle = {Proceedings of the 27th International Conference on Parallel Architectures and Compilation Techniques},
  doi = {10.1145/3243176.3243195},
  publisher = {{ACM} Press},
  series = {PACT'18},
  title = {Biased Reference Counting},
  url = {https://iacoma.cs.uiuc.edu/iacoma-papers/pact18.pdf},
  year = 2018,

  vm:concepts = {Garbage Collection},
  vm:shortTitle = {Reachability for Dynamic Atomic Reference Counting},
  vm:edge:similar = {Ungar:17:DA similar with bias towards a thread}
}

@inproceedings{Roberts:2019:TTAF,
  abstract = {Transient gradual typing imposes run-time type tests that typically cause a linear slowdown. This performance impact discourages the use of type annotations because adding types to a program makes the program slower. A virtual machine can employ standard just-in-time optimizations to reduce the overhead of transient checks to near zero. These optimizations can give gradually-typed languages performance comparable to state-of-the-art dynamic languages, so programmers can add types to their code without affecting their programs' performance.},
  appendix = {https://github.com/gracelang/moth-benchmarks/blob/papers/ecoop19/index.md},
  author = {Roberts, Richard and Marr, Stefan and Homer, Michael and Noble, James},
  booktitle = {33rd European Conference on Object-Oriented Programming},
  day = 15,
  doi = {10.4230/LIPIcs.ECOOP.2019.5},
  isbn = {978-3-95977-111-5},
  issn = {1868-8969},
  month = {July},
  number = 5,
  pages = {5:1--5:28},
  url = {https://stefan-marr.de/downloads/ecoop19-roberts-et-al-transient-typechecks-are-almost-free.pdf},
  publisher = {Schloss Dagstuhl--Leibniz-Zentrum fuer Informatik},
  series = {ECOOP'19},
  title = {Transient Typechecks are (Almost) Free},
  volume = 134,
  year = 2019,

  vm:concepts = {Optimization, Gradual Typing},
  vm:shortTitle = {Optimizing Gradual Typing on GraalVM},
  vm:edge:uses = {Woss:14:TOM;Marr:15:DC}
}



@inproceedings{Cheng:2020:TF,
  author = {Cheng, Lin and Ilbeyi, Berkin and Bolz-Tereick, Carl Friedrich and Batten, Christopher},
  booktitle = {Proceedings of the 18th {ACM}/{IEEE} International Symposium on Code Generation and Optimization},
  description = {Type freezing: exploiting attribute type monomorphism in tracing JIT compilers | Proceedings of the 18th ACM/IEEE International Symposium on Code Generation and Optimization},
  doi = {10.1145/3368826.3377907},
  month = feb,
  publisher = {ACM},
  series = {CGO'20},
  title = {Type Freezing: Exploiting Attribute Type Monomorphism in Tracing JIT Compilers},
  url = {https://dl.acm.org/doi/abs/10.1145/3368826.3377907},
  year = 2020,

  vm:shortTitle = {Type Freezing Maps},
  vm:edge:extends = {Woss:14:TOM + nested type freezing}
}

  `));
})

var dotIndex = 0;
var graphviz = d3.select("#graph").graphviz()
    .transition(function () {
        return d3.transition("main")
            .ease(d3.easeLinear)
            .delay(100)
            .duration(500);
    })
    .logEvents(true)
    .on("initEnd", triggerRender);

let triggerRenderResolve;
const triggerRenderP = new Promise(function(resolve, reject) {
  triggerRenderResolve = resolve;
});

function triggerRender() {
  triggerRenderResolve();
}

Promise.all([dataPromise, triggerRenderP]).then(function(values) {
  const dot = values[0];
  graphviz.renderDot(dot);
});
</script>
</html>